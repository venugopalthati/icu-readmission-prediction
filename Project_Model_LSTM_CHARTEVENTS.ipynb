{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "673484fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import imblearn\n",
    "\n",
    "from numpy import where\n",
    "from matplotlib import pyplot\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78d4316",
   "metadata": {},
   "source": [
    "## Load numpy arrays from the path where process icustays program saved those arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7c18cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48854, 48, 59)\n",
      "(48854, 14)\n",
      "(48854, 17)\n",
      "(48854,)\n"
     ]
    }
   ],
   "source": [
    "path = Path('/finalproject/npoutput').expanduser()\n",
    "\n",
    "chart_data_np = np.load(path/'chart_all_data_04272109.npy')\n",
    "demographic_data_np = np.load(path/'demographic_all_data_04272109.npy')\n",
    "icd9_data_np = np.load(path/'icd9_all_data_04272109.npy')\n",
    "y_np = np.load(path/'y_all_04272109.npy')\n",
    "\n",
    "\n",
    "\n",
    "print(chart_data_np.shape)\n",
    "print(demographic_data_np.shape)\n",
    "print(icd9_data_np.shape)\n",
    "print(y_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d105bec4",
   "metadata": {},
   "source": [
    "## Oversample positive icustays as there is data imbalance between positive and negative icustays in the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af3a9cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 39227, 1.0: 9627})\n",
      "(48854, 48, 59)\n",
      "(48854,)\n",
      "(48854, 48, 59)\n",
      "(78454,)\n",
      "Counter({0.0: 39227, 1.0: 39227})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y_np)\n",
    "print(counter)\n",
    "\n",
    "#chart_data_transposed = chart_data_np.transpose(2,0,1).reshape(3,-1)\n",
    "chart_data_np_reshape = chart_data_np.reshape(len(chart_data_np),-1)\n",
    "print(chart_data_np.shape)\n",
    "\n",
    "print(y_np.shape)\n",
    "oversample = SMOTE()\n",
    "chart_data_np_reshape, y_np1 = oversample.fit_resample(chart_data_np_reshape, y_np)\n",
    "# summarize the new class distribution\n",
    "chart_data_np_1 = chart_data_np_reshape.reshape(len(chart_data_np_reshape),48,59)\n",
    "counter = Counter(y_np1)\n",
    "print(chart_data_np.shape)\n",
    "print(y_np1.shape)\n",
    "print(counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49279749",
   "metadata": {},
   "source": [
    "## Convert numpy arrays to pytorch arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dac2bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_data = torch.from_numpy(chart_data_np_1).float()\n",
    "demographic_data = torch.from_numpy(demographic_data_np).float()\n",
    "icd9_data = torch.from_numpy(icd9_data_np).float()\n",
    "y = torch.from_numpy(y_np1).float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfede3dc",
   "metadata": {},
   "source": [
    "## Create CustomDataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9e4c012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "\n",
    "dataset = CustomDataset(chart_data, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a1416b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CustomDataset object at 0x13858f820>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1668de51",
   "metadata": {},
   "source": [
    "## Collate function to collect batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "006479a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    #print(len(data))\n",
    "    x, y = zip(*data)\n",
    "    return torch.stack(x), torch.stack(y).type(torch.LongTensor) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d76c8e6",
   "metadata": {},
   "source": [
    "## Split dataset into 80% training, 10% validation and 10% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33f8f3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 62763\n",
      "Length of val dataset: 7845\n",
      "Length of test dataset: 7846\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "split = int(len(dataset)*0.8)\n",
    "\n",
    "lengths = [split, len(dataset) - split]\n",
    "train_dataset, rem_dataset = random_split(dataset, lengths)\n",
    "\n",
    "val_test_split = int(len(rem_dataset)*0.5)\n",
    "\n",
    "val_test_lengths = [val_test_split, len(rem_dataset) - val_test_split]\n",
    "val_dataset, test_dataset = random_split(rem_dataset, val_test_lengths)\n",
    "\n",
    "\n",
    "print(\"Length of train dataset:\", len(train_dataset))\n",
    "print(\"Length of val dataset:\", len(val_dataset))\n",
    "print(\"Length of test dataset:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ba8081",
   "metadata": {},
   "source": [
    "## Create dataloaders for the train, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7d91b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def load_data(train_dataset, val_dataset, test_dataset, collate_fn):\n",
    "    \n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = load_data(train_dataset, val_dataset, test_dataset, collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dfc2ab",
   "metadata": {},
   "source": [
    "## Create Bi-directional LSTM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca1af392",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.lstm = nn.LSTM(input_size=58, hidden_size=58, bidirectional= True, batch_first=True, num_layers=3)\n",
    "        self.lstm = nn.LSTM(input_size=59, hidden_size=59, bidirectional=True, batch_first=True, num_layers=1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.lstmdropout = nn.Dropout()\n",
    "        \n",
    "        #self.fc1 = nn.Linear(8233, 256)\n",
    "        #self.fc1 = nn.Linear(5473, 256)\n",
    "        self.fc1 = nn.Linear(118, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        #self.fc2 = nn.Linear(116, 10)\n",
    "        self.fc3 = nn.Linear(10, 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        #print('batch_size', batch_size)\n",
    "        #print('x shape', x.shape)\n",
    "        output,(h,c) = self.lstm(x)\n",
    "        #print('output shape', output.shape)\n",
    "        #print('h shape', h.shape)\n",
    "        #print('h shape', h[0].shape,h[-1].shape)\n",
    "        finaloutput = torch.concat([h[0],h[-1]],dim=1)\n",
    "        #print('finaloutput shape',finaloutput.shape)\n",
    "        \n",
    "        #print(finaloutput.shape)\n",
    "        finaloutput = self.lstmdropout(self.tanh(finaloutput))\n",
    "        #print('after forward', finaloutput.shape)\n",
    "        \n",
    "            \n",
    "        finaloutput = self.sigmoid(self.fc3(self.fc2(self.fc1(finaloutput))))\n",
    "        #print('after sigmoid', finaloutput.shape)\n",
    "        #for i in range(48):\n",
    "        #    print(finaloutput[1,i,0],finaloutput[1,i,1])\n",
    "        \n",
    "        #print(finaloutput[0,1,0],finaloutput[0,1,1])\n",
    "        #print(finaloutput[0,2,0],finaloutput[0,2,1])\n",
    "        \n",
    "        #print(finaloutput.shape)\n",
    "        #finaloutput = torch.squeeze(finaloutput, 1)\n",
    "        return finaloutput\n",
    "    \n",
    "model = LSTM() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3185a942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(59, 59, batch_first=True, bidirectional=True)\n",
       "  (tanh): Tanh()\n",
       "  (lstmdropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=118, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (fc3): Linear(in_features=10, out_features=2, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0316fdad",
   "metadata": {},
   "source": [
    "## Print number of parameters used by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a8ab0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63122"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ef2d26",
   "metadata": {},
   "source": [
    "## Create Adam optimizer and Cross Entropy Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbf8a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af5450",
   "metadata": {},
   "source": [
    "## Model evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90984d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "def eval_model(model, val_loader):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = torch.LongTensor()\n",
    "    model.eval()\n",
    "    for x, y in val_loader:\n",
    "        y_hat = model(x)\n",
    "        #y_score = torch.cat((y_score,  y_hat.detach().to('cpu')), dim=0)\n",
    "        y_hat = (y_hat > 0.5).int()\n",
    "        #print(y_hat.shape)\n",
    "        for i in range(len(y_hat)):\n",
    "            if y_hat[i][0] == 1:\n",
    "                y_pred.append(0)\n",
    "            else:\n",
    "                y_pred.append(1)\n",
    "        #y_pred = torch.cat((y_pred,  y_hat.detach().to('cpu')), dim=0)\n",
    "        y_true = torch.cat((y_true, y.detach().to('cpu')), dim=0)\n",
    "    \n",
    "    y_pred_t = torch.Tensor(y_pred)\n",
    "    #print(y_pred_t)\n",
    "    #print(y_true)\n",
    "    acc = accuracy_score(y_true, y_pred_t)\n",
    "    precision = precision_score(y_true, y_pred_t)\n",
    "    recall = recall_score(y_true, y_pred_t)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_t)\n",
    "    \n",
    "    return acc, precision, recall, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0f4432",
   "metadata": {},
   "source": [
    "## Unit test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7ebe81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5523263224984066 0.5395909805977976 0.778562421185372 0.5498482209019644\n"
     ]
    }
   ],
   "source": [
    "a, p, r, roc_auc = eval_model(model, val_loader)\n",
    "print(a, p, r, roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b54677",
   "metadata": {},
   "source": [
    "## Training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6a057d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "def train(model, train_loader, val_loader, n_epochs):\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            #print(len(x))\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            #print(y_hat)\n",
    "            #print(y)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        print('Epoch: {} \\t Training Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "        a, p, r, roc_auc = eval_model(model, val_loader)\n",
    "        print('Epoch: {} \\t Validation a: {:.3f}, p:{:.3f}, r: {:.3f}, roc_auc: {:.3f}'\n",
    "              .format(epoch+1, a, p, r, roc_auc))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55fff75",
   "metadata": {},
   "source": [
    "## Call the training function for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b560a06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Training Loss: 0.593112\n",
      "Epoch: 1 \t Validation a: 0.771, p:0.826, r: 0.693, roc_auc: 0.772\n",
      "Epoch: 2 \t Training Loss: 0.537764\n",
      "Epoch: 2 \t Validation a: 0.783, p:0.841, r: 0.703, roc_auc: 0.784\n",
      "Epoch: 3 \t Training Loss: 0.543931\n",
      "Epoch: 3 \t Validation a: 0.759, p:0.766, r: 0.754, roc_auc: 0.759\n",
      "Epoch: 4 \t Training Loss: 0.522419\n",
      "Epoch: 4 \t Validation a: 0.796, p:0.876, r: 0.694, roc_auc: 0.797\n",
      "Epoch: 5 \t Training Loss: 0.513530\n",
      "Epoch: 5 \t Validation a: 0.801, p:0.912, r: 0.672, roc_auc: 0.803\n",
      "Epoch: 6 \t Training Loss: 0.510784\n",
      "Epoch: 6 \t Validation a: 0.802, p:0.924, r: 0.663, roc_auc: 0.804\n",
      "Epoch: 7 \t Training Loss: 0.502865\n",
      "Epoch: 7 \t Validation a: 0.817, p:0.936, r: 0.685, roc_auc: 0.818\n",
      "Epoch: 8 \t Training Loss: 0.513423\n",
      "Epoch: 8 \t Validation a: 0.808, p:0.915, r: 0.683, roc_auc: 0.809\n",
      "Epoch: 9 \t Training Loss: 0.499708\n",
      "Epoch: 9 \t Validation a: 0.815, p:0.974, r: 0.651, roc_auc: 0.817\n",
      "Epoch: 10 \t Training Loss: 0.491761\n",
      "Epoch: 10 \t Validation a: 0.815, p:0.984, r: 0.644, roc_auc: 0.817\n",
      "end_time_nanosec 1651187769509502000\n",
      "total time in seconds 263.426012\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time_nanosec = time.time_ns()\n",
    "\n",
    "n_epochs = 10\n",
    "train(model, train_loader, val_loader, n_epochs)\n",
    "\n",
    "end_time_nanosec = time.time_ns()\n",
    "print('end_time_nanosec', end_time_nanosec)\n",
    "\n",
    "\n",
    "print('total time in seconds', (end_time_nanosec - start_time_nanosec)/1000000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8267e7bf",
   "metadata": {},
   "source": [
    "## Evaluate the model on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecf35a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \t Testing a: 0.820, p:0.980, r: 0.649, roc_auc: 0.818\n"
     ]
    }
   ],
   "source": [
    "a, p, r, roc_auc = eval_model(model, test_loader)\n",
    "print('Epoch: {} \\t Testing a: {:.3f}, p:{:.3f}, r: {:.3f}, roc_auc: {:.3f}'\n",
    "              .format(1, a, p, r, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecd3000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
